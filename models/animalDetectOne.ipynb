{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense, GlobalAveragePooling2D\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmobilenet_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m MobileNetV2, preprocess_input\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelBinarizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability = None\n",
    ")\n",
    "\n",
    "print(\"Num GPUs Available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Preprocessor class\n",
    "\n",
    "class ImagePreprocessor:\n",
    "    def __init__(self, root_dir, desired_size=(128, 128)):\n",
    "        self.root_dir = root_dir\n",
    "        self.desired_size = desired_size\n",
    "        ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator\n",
    "\n",
    "        self.datagen = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            zoom_range=0.15,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.15,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode=\"nearest\"\n",
    "        )\n",
    "        \n",
    "    def _load_image(self, path):\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        image = cv2.resize(image, self.desired_size)\n",
    "        return image\n",
    "    \n",
    "    def process_images(self):\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for label in os.listdir(self.root_dir):\n",
    "            class_path = os.path.join(self.root_dir, label)\n",
    "            if os.path.isdir(class_path):\n",
    "                for filename in os.listdir(class_path):\n",
    "                    filepath = os.path.join(class_path, filename)\n",
    "                    if filepath.lower().endswith(('.jpg', '.jpeg')):\n",
    "                        image = self._load_image(filepath)\n",
    "                        images.append(image)\n",
    "                        labels.append(label)\n",
    "        \n",
    "        # Convert images and labels to arrays\n",
    "        images = np.array(images) / 255.0\n",
    "        labels = np.array(labels)\n",
    "        print(\"Unique Labels: \", np.unique(labels))\n",
    "\n",
    "        # One-hot encode labels\n",
    "        lb = LabelBinarizer()\n",
    "        labels = lb.fit_transform(labels)\n",
    "        return images, labels\n",
    "\n",
    "    def get_train_val_test(self, test_size=0.2, val_size=0.1):\n",
    "        images, labels = self.process_images()\n",
    "        trainX, testX, trainY, testY = train_test_split(images, labels, test_size=test_size)\n",
    "        trainX, valX, trainY, valY = train_test_split(trainX, trainY, test_size=val_size / (1 - test_size))\n",
    "        \n",
    "        return (trainX, trainY), (valX, valY), (testX, testY)\n",
    "\n",
    "    def save_processed_images(self, save_dir):\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        images, labels = self.process_images()\n",
    "\n",
    "        #Save images as file name\n",
    "\n",
    "        for idx, (image, label) in enumerate(zip(images, labels)):\n",
    "            label_str = str(np.argmax(label))\n",
    "            filename = f\"{label_str}_{idx}.jpg\"\n",
    "            filepath = os.path.join(save_dir, filename)\n",
    "\n",
    "            # Convert the image back to the range [0, 255]\n",
    "            image_to_save = (image * 255).astype(np.uint8)\n",
    "\n",
    "            cv2.imwrite(filepath, cv2.cvtColor(image_to_save, cv2.COLOR_RGB2BGR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MobileNetV2 without top layer\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average Pooling Layer\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "#fully-connected layer \n",
    "\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "\n",
    "# softmax layer for classification\n",
    "\n",
    "num_classes = len(os.listdir(\"C:\\\\Users\\\\bcurl\\\\Desktop\\\\AnimalDetect\\\\data\\\\raw-img\")) \n",
    "\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "#trained models\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze pre trained layers\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model \n",
    "\n",
    "model.compile(optimizer = 'adam', loss='categorical_crossentropy',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process images \n",
    "\n",
    "preprocessor = ImagePreprocessor(\"C:\\\\Users\\\\bcurl\\\\Desktop\\\\AnimalDetect\\\\data\\\\raw-img\")\n",
    "(trainX, trainY), (valX, valY), (testX, testY) = preprocessor.get_train_val_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model with the new layers for some epochs\n",
    "\n",
    "model.fit(trainX, trainY, validation_data=(valX, valY), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anDetect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
