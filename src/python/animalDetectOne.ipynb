{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bcurl\\AppData\\Local\\Temp\\ipykernel_10992\\2938471607.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Num GPUs Available:  []\n"
     ]
    }
   ],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability = None\n",
    ")\n",
    "\n",
    "print(\"Num GPUs Available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Preprocessor class\n",
    "\n",
    "class ImagePreprocessor:\n",
    "    def __init__(self, root_dir, desired_size=(128, 128)):\n",
    "        self.root_dir = root_dir\n",
    "        self.desired_size = desired_size\n",
    "        ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator\n",
    "\n",
    "        self.datagen = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            zoom_range=0.15,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.15,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode=\"nearest\"\n",
    "        )\n",
    "        \n",
    "    def _load_image(self, path):\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        image = cv2.resize(image, self.desired_size)\n",
    "        return image\n",
    "    \n",
    "    def process_images(self):\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for label in os.listdir(self.root_dir):\n",
    "            class_path = os.path.join(self.root_dir, label)\n",
    "            if os.path.isdir(class_path):\n",
    "                for filename in os.listdir(class_path):\n",
    "                    filepath = os.path.join(class_path, filename)\n",
    "                    if filepath.lower().endswith(('.jpg', '.jpeg')):\n",
    "                        image = self._load_image(filepath)\n",
    "                        images.append(image)\n",
    "                        labels.append(label)\n",
    "        \n",
    "        # Convert images and labels to arrays\n",
    "        images = np.array(images) / 255.0\n",
    "        labels = np.array(labels)\n",
    "        print(\"Unique Labels: \", np.unique(labels))\n",
    "\n",
    "        # One-hot encode labels\n",
    "        lb = LabelBinarizer()\n",
    "        labels = lb.fit_transform(labels)\n",
    "        return images, labels\n",
    "\n",
    "    def get_train_val_test(self, test_size=0.2, val_size=0.1):\n",
    "        images, labels = self.process_images()\n",
    "        trainX, testX, trainY, testY = train_test_split(images, labels, test_size=test_size)\n",
    "        trainX, valX, trainY, valY = train_test_split(trainX, trainY, test_size=val_size / (1 - test_size))\n",
    "        \n",
    "        return (trainX, trainY), (valX, valY), (testX, testY)\n",
    "\n",
    "    def save_processed_images(self, save_dir):\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        images, labels = self.process_images()\n",
    "\n",
    "        #Save images as file name\n",
    "\n",
    "        for idx, (image, label) in enumerate(zip(images, labels)):\n",
    "            label_str = str(np.argmax(label))\n",
    "            filename = f\"{label_str}_{idx}.jpg\"\n",
    "            filepath = os.path.join(save_dir, filename)\n",
    "\n",
    "            # Convert the image back to the range [0, 255]\n",
    "            image_to_save = (image * 255).astype(np.uint8)\n",
    "\n",
    "            cv2.imwrite(filepath, cv2.cvtColor(image_to_save, cv2.COLOR_RGB2BGR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "#Load MobileNetV2 without top layer\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average Pooling Layer\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "#fully-connected layer \n",
    "\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "\n",
    "# softmax layer for classification\n",
    "\n",
    "num_classes = len(os.listdir(\"C:\\\\Users\\\\bcurl\\\\Desktop\\\\AnimalDetect\\\\data\\\\raw-img\")) \n",
    "\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "#trained models\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze pre trained layers\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model \n",
    "\n",
    "model.compile(optimizer = 'adam', loss='categorical_crossentropy',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Labels:  ['butterfly' 'cat' 'chicken' 'cow' 'dog' 'elephant' 'horse' 'sheep'\n",
      " 'spider' 'squirrel']\n"
     ]
    }
   ],
   "source": [
    "#process images \n",
    "\n",
    "preprocessor = ImagePreprocessor(\"C:\\\\Users\\\\bcurl\\\\Desktop\\\\AnimalDetect\\\\data\\\\raw-img\")\n",
    "(trainX, trainY), (valX, valY), (testX, testY) = preprocessor.get_train_val_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "572/572 [==============================] - 98s 166ms/step - loss: 0.4325 - accuracy: 0.8704 - val_loss: 0.3707 - val_accuracy: 0.8775\n",
      "Epoch 2/10\n",
      "572/572 [==============================] - 92s 161ms/step - loss: 0.2372 - accuracy: 0.9208 - val_loss: 0.3262 - val_accuracy: 0.8990\n",
      "Epoch 3/10\n",
      "572/572 [==============================] - 91s 159ms/step - loss: 0.1730 - accuracy: 0.9419 - val_loss: 0.3692 - val_accuracy: 0.8860\n",
      "Epoch 4/10\n",
      "572/572 [==============================] - 91s 159ms/step - loss: 0.1205 - accuracy: 0.9586 - val_loss: 0.3616 - val_accuracy: 0.8948\n",
      "Epoch 5/10\n",
      "572/572 [==============================] - 91s 160ms/step - loss: 0.0854 - accuracy: 0.9704 - val_loss: 0.4420 - val_accuracy: 0.8814\n",
      "Epoch 6/10\n",
      "572/572 [==============================] - 90s 157ms/step - loss: 0.0690 - accuracy: 0.9764 - val_loss: 0.4120 - val_accuracy: 0.8982\n",
      "Epoch 7/10\n",
      "572/572 [==============================] - 91s 159ms/step - loss: 0.0558 - accuracy: 0.9814 - val_loss: 0.4811 - val_accuracy: 0.9039\n",
      "Epoch 8/10\n",
      "572/572 [==============================] - 91s 158ms/step - loss: 0.0536 - accuracy: 0.9821 - val_loss: 0.4913 - val_accuracy: 0.8971\n",
      "Epoch 9/10\n",
      "572/572 [==============================] - 90s 158ms/step - loss: 0.0380 - accuracy: 0.9864 - val_loss: 0.5223 - val_accuracy: 0.8993\n",
      "Epoch 10/10\n",
      "572/572 [==============================] - 89s 156ms/step - loss: 0.0388 - accuracy: 0.9875 - val_loss: 0.6491 - val_accuracy: 0.8913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e6bc733f70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model with the new layers for some epochs\n",
    "\n",
    "model.fit(trainX, trainY, validation_data=(valX, valY), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"animal_detection_model_1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 22s 137ms/step - loss: 0.6399 - accuracy: 0.8986\n",
      "Test Loss: 0.6398894786834717\n",
      "Test Accuracy: 0.8985840082168579\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(testX, testY)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anDetect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
